title: 資料品質為什麼很重要? 如何監控資料品質?
authors: MingLun Allen Wu
date: 2021-12-24 12:00:00
tags: 待定
category: 待定
summary: 待定
slug: data_quality
top_image: https://images.unsplash.com/photo-1488229297570-58520851e868?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80

# TL;DR

在資料分析的領域中，資料品質有點像是「溫室效應」: **大家都知道它很重要，卻不是每個人都想花時間處理，然後有一天，就Fucked Up了**。

近期試著在部門建立監控資料品質的機制，透過這篇文章記錄過程中建立的知識點，以及最後是怎麼實作出可套用在現行數百個 ETL 的監控模組。

# 到底哪裡出了問題?

大約半年前，我正在前一份工作建模，在確定了基本的模型架構後，使用手邊現有的資料進行預測，結果相當不錯! 團隊歡欣鼓舞。

到了下個月，新的資料收集完畢，丟進一樣的模型做預測，結果**慘不忍睹**，團隊成員面面相覷。

欸! 你有改模型的架構嗎?

沒...沒有阿...?

會不會這個月的資料本來就怪怪的啊...?

我...我也不知道欸...

<img style="display:block; margin-left:auto; margin-right:auto; width:100%;" src="https://minglunwu.github.io/images/20211224/why.png">


模型的架構，可以透過**程式碼版控**去追蹤每個版本的更動。

而每一批資料的變動是否有異常的情況發生，這就需要花點工夫深入了解了。

# 對建模的迷思

剛踏入資料分析的領域時，有種迷思:

> 預測結果不好，一定是這個模型架構太爛了!

所以花了很多時間去追最新的模型架構、研讀新的論文，陷入了一種「套件工程師」的感覺: **把相同的資料，丟進不同的模型試試，如果表現不好，就再換一種模型**。

直到上了 Andrew Ng. 的 Coursera 課程 - <a href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops?#courses">MLOps Specialization</a>

其中分享了一個觀念: `Model-Centric` 與 `Data-Centric` AI 的不同，分別透過`改善模型`及`改善資料`來達到優化結果的目的。

在 Andrew 公司內部的多個專案中，他們發現`改善資料`的改善幅度是遠大於`改善模型`的。要做到`改善資料`，勢必要深入的瞭解資料。

如果有興趣的讀者，也可以看看以下影片: 

<iframe style="display:block; margin-left:auto; margin-right:auto; width:100%;" height=315 src="https://www.youtube.com/embed/06-AZXmwHjo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<br>
此外，當模型上線運行後，一但Inference資料的分布發生異常，很容易造成模型表現一落千丈，這種情況常被稱為 `Data Drift` (資料偏移)，透過計算資料品質，能夠盡早發現這樣的狀況。

# 資料品質

## 不同面向、難有統一標準

如果要對資料品質進行較明確的定義，我會這麼形容: 

> 透過指標來評估資料的狀況是否正確及可靠

實際上資料品質涵蓋了許多不同的面向:

+ 完整度
+ 一致性
+ 使用性
+ 可靠性
+ 時效性

這些面向中，很難找到一組標準是「放諸四海皆準」，適用於所有的情況。基本上這些指標是**因應各個分析團隊的需求而異**。

舉個例子來說: 一批資料缺少了生日欄位，對某些團隊來說，這樣是「無法接受」的，因為少了可以運用的 Feature。但對於銀行的分析團隊來說，這樣才是「合法」的，因為金融法規有規定做分析前需要進行「去識別化」。

## 資料品質標準化

許多公司其實都有推行自己的資料品質監控平台: 

+ AWS: Amazon建立了`Deequ`這個工具，用來進行資料品質的計算，並且據此建構了內部的資料品質計算工具 - <a href="https://aws.amazon.com/tw/blogs/big-data/test-data-quality-at-scale-with-deequ/">Test data quality at scale with Deequ</a>
+ Uber: Uber 則分享內部的 `UDQ`(Uber Data Quality Platform)是如何運作的 - <a href="https://eng.uber.com/operational-excellence-data-quality/">How Uber Achieves Operational Excellence in the Data Quality Experience</a>

其中 `Uber` 在文章中分享到建立平台前，他們向內部的 Data Consumer 和 Data Producer 分別收集了相關需求，在五花八門的需求中，梳理出幾個類別: 

| 類別 | 定義 |
|:----:|:----:|
|Completeness| 資料完整度，從上游任務轉到下游任務時，資料的完整程度 |
|Freshness| 資料轉移過程中，達到99.9%完整度所需的時間 |
|Duplicates| 一批資料中，主鍵是唯一的比例 |
|Cross-Datacenter Consistency| 該批資料與其他資料中心的一致程度 |
|Others| 使用者自行定義，無其他標準 |



