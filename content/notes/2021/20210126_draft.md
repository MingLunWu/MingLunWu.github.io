---
title: MLFlow Project 筆記
author: MingLun Allen Wu
date: 2021-01-26
tags: 
  - MLFlow
category: []
summary: 
slug: mlflow_project
image: https://images.unsplash.com/photo-1484669970465-b0c50d7f6964?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=2089&q=80
published: false
---
# Intro 

`MLFlow Project` 是 `MLFlow` 四大工具之一 (`Tracking`, `Models`, `Models Registry`)

對於 `Tracking` 有興趣的朋友，歡迎先回顧之前的文章: 

<a href="https://minglunwu.github.io/notes/2020/20200527.html">不再被大量超參數及模型表現淹沒！使用MLFlow進行實驗管理</a>

`MLFlow Tracking` 協定、讓其他資料使用者 or 工具 能夠執行。

每個Project可以是：

+ 資料夾
+ Git Repository

在資料夾中放置 `MLproject` 檔案來進行設定 : 

+ Name: Readable Name
+ Entry Point: 此專案可以被執行的指令、參數說明
+ Environment: 可以使用 `conda`, `docker`, `system`
  + `conda`: 執行前會 activate 環境。
    + 資料夾中的 `conda.yaml`   
    + `MLproject`中的`conda_env` entrypoint
  + `Docker` : 可以存放 non-python的dependency like Java
    + 執行 mlflow project時，會自動建立新的 image，並且把當前資料夾複製到Docker中的 `/mlflow/projects/code`，並且自動將你寫在`MLproject`中的`entrypoint`當成是 Docker的 `entrypoint`

如果沒有存放 `MLproject` 時， `MLflow Project` 會按照下列規則: 

+ 資料夾名稱就是Project名稱
+ `conda.yml`紀錄 conda 環境，如果資料夾中沒有`conda.yml`，則Mlflow會自動建立一個空的conda環境只包含Python
+ 任何 `.py` 或是 `.sh`結尾的檔案都將成為 entry point.


About `MLProject`, `yaml` format: 

    :::yaml
    name: My Project

    conda_env: my_env.yaml # Conda 的 yaml檔案路徑
    # Can have a docker_env instead of a conda_env, e.g.
    # docker_env:
    #    image:  mlflow-docker-example # 從系統端找，若找不到會嘗試從docker-hub pull 下來
    #    volumes: ["/local/path:/container/mount/path"]  # Local Volume
    #    environment: [["NEW_ENV_VAR", "new_var_value"], "VAR_TO_COPY_FROM_HOST_ENVIRONMENT"] # 定義一個新環境變數，及取用一個既有的環境變數
  

    entry_points:
    main:
        parameters: # 定義參數
        data_file: path
        regularization: {type: float, default: 0.1}
        command: "python train.py -r {regularization} {data_file}" # 所有定義在參數區塊中的變數，都可以透過Python string format送入
    validate:
        parameters:
        data_file: path
        command: "python validate.py {data_file}"

# Specify Parameter 
MLFlow 可以定義參數的初始值及資料型態

    :::yaml
    parameter_name: {type: data_type, default: value}  # Short syntax

    parameter_name:     # Long syntax
    type: data_type
    default: value

資料型態可以是 : 
    
+ string
+ float
+ path (local file)
+ uri (for distributed system like spark)

# Running Projects

可以使用下列任一方式使用: 

+ Command-Line Tool
+ Python API `mlflow.projects.run()

**也就是說如果我有一個Git Repo，並且本地端有安裝conda或是docker，那麼我連clone都不用，直接透過mlflow project即可直接執行**

並且在執行過程中可以選擇: 

+ Project Version (哪一個git commit)
+ Entry Point (執行哪一個Entry Point, Default to `main`)
+ Parameters: Key-Value Parameters (Ex: -P alpha=0.5)
+ Deployment Mode: K8S or other remote server.
+ Environment: 也可以直接在`MLproject`中設定，或是使用``--no-conda` flag 使用當前的環境。

所以如果使用 `MLProject` 的話:

1. Script都要用 argparse 來接受參數
2. `MLproject` 中的entrypoint接受參數並傳入檔案
3. 執行時，就能搭配 MLFlow 的 Tracker功能快速迭代運行！！

可以同時啟動Multiple Runs

## MLFlow tracking server

> MLFlow tracking 的資訊要存放在哪裡？

原先是「專案執行的資料夾」 -> 可以改成「本地「的一個位置

  :::bash
  mlflow server \
    --backend-store-uri /mnt/persistent-disk \
    --default-artifact-root s3://my-mlflow-bucket/ \
    --host 0.0.0.0

Tracking Server 有兩個儲存元件：

1. Backend Store (Experiment, run metadata)
  + file store
  + database-backed store
2. Artiface Store (儲存大型Ckpt檔案)
  + 各項雲端服務

# MLFlow Models

ML Model 的標準儲存格式，有許多不同的 `Flavor` :

+ `Python Function` Flavor ：描述如何將 model 當成 `Python` function 執行。

> 將模型轉換為「常見的工具」可支援的模式。(例如直接把checkpoint打包成可供執行的Python Function)