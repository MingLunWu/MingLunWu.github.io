<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
        <!--- basic page needs
    ================================================== -->
    <meta charset="utf-8">
    <!--
    <meta name="description" content="">
    <meta name="author" content="">
    -->
    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/base.css">
    <!--<link rel="stylesheet" href="https://minglunwu.github.io/theme/css/vendor.css">-->
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/main.css">
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/styles.css">

    <!-- script
    ================================================== -->
    <script src="https://minglunwu.github.io/theme/js/modernizr.js"></script>
    <script src="https://minglunwu.github.io/theme/js/pace.min.js"></script>
    <!--<script src="https://kit.fontawesome.com/968a4ded4c.js" crossorigin="anonymous"></script>-->

    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="https://minglunwu.github.io/theme/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://minglunwu.github.io/theme/favicon.ico" type="image/x-icon">

    <title>從零開始 - Pytorch 入門懶人包</title>
    <meta property="og:title" content="從零開始 - Pytorch 入門懶人包">
    <meta name="description" content="<p>研究所時有花時間去了解Neural Network的概念，但卻一直沒有機會進行實作，最近有機會可以從頭開始學習Pytorch，把學習的過程整理記錄下來，希望想要快速上手Pytorch的人，可以透過這篇文章快速入門！</p>">
    <meta property="og:description" content="<p>研究所時有花時間去了解Neural Network的概念，但卻一直沒有機會進行實作，最近有機會可以從頭開始學習Pytorch，把學習的過程整理記錄下來，希望想要快速上手Pytorch的人，可以透過這篇文章快速入門！</p>">
    <meta name="author" content="MingLun Allen Wu">
    <meta property="og:image" content="https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80">
    
    <link rel="image_src" type="image/jpeg" href="https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80" />
    <style>
        img{
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
    </style>
</head>

<body id="top">
            <!-- header
    ================================================== -->
    <header class="s-header">

        <div class="header-logo">
            <a class="site-logo" href="https://minglunwu.github.io"><img src="https://minglunwu.github.io/theme/images/logo.png" width="160" height="56" alt="Homepage"></a>
        </div>

        <nav class="header-nav-wrap">
            <ul class="header-nav">
                <li class="current"><a href="https://minglunwu.github.io/#home" title="home">Home</a></li>
                <li><a href="https://minglunwu.github.io/#about" title="about">About</a></li>
                <li><a href="https://minglunwu.github.io/#blog" title="blog">Blogs</a></li>
                <li><a href="https://minglunwu.github.io/#note" title="note">Notes</a></li>
                <!--<li><a class="smoothscroll" href="#note" title="notes">Notes</a></li>-->
                <!--<li><a class="smoothscroll"  href="#contact" title="contact">Contact</a></li>-->
            </ul>
        </nav>

        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->

        <article class="blog-single">

            <!-- page header/blog hero
            ================================================== -->
            <div class="page-header page-header--single page-hero" style="background-image:url(https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80)">
            
                <div class="row page-header__content narrow">
                    <article class="col-full">
                        <div class="page-header__info">
                            <div class="page-header__cat">
                                    <a href="#0">Pytorch</a>
                            </div>
                        </div>
                        <h1 class="page-header__title">
                            <a href="#0" title="">
                                從零開始 - Pytorch 入門懶人包
                            </a>
                        </h1>
                        <ul class="page-header__meta">
                            <li class="date">2020- 3-24 (二)</li>
                            <li class="author">
                                By
                                <span>MingLun Allen Wu</span>
                            </li>
                        </ul>
                        
                    </article>
                </div>
        
            </div> <!-- end page-header -->
    
            <div class="row blog-content">
                <div class="col-full blog-content__main">
                    
                    <h1>前言</h1>
<p>研究所時有花時間去了解Neural Network的概念，但卻一直沒有機會進行實作，最近有機會可以從頭開始學習Pytorch，把學習的過程整理記錄下來，希望想要快速上手Pytorch的人，可以透過這篇文章快速入門！
<!--more--></p>
<h1>目錄</h1>
<ol>
<li><a href="#前言">前言</a></li>
<li><a href="#目錄">目錄</a></li>
<li><a href="#Tensor的基本使用、格式轉換">Tensor的基本使用、格式轉換</a></li>
<li><a href="#常會使用到的Module">常會使用到的Module</a></li>
<li><a href="#建立一個Network">建立一個Network</a></li>
<li><a href="#建立訓練資料集">建立訓練資料集</a></li>
<li><a href="#訓練的Pipeline">訓練的Pipeline</a></li>
<li><a href="#視覺化工具-TensorBoard">視覺化工具-TensorBoard</a></li>
<li><a href="#儲存、載入Model">儲存、載入Model</a></li>
<li><a href="#使用GPU">使用GPU</a></li>
</ol>
<hr>
<h1>Tensor的基本使用、格式轉換</h1>
<h2>建立Tensor</h2>
<div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">tensor_a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>


<h2>Tensor 的維度轉換</h2>
<div class="highlight"><pre><span></span><span class="n">tensor_reshape</span> <span class="o">=</span> <span class="n">tensor_a</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<h2>Tensor 中的元素型態轉換</h2>
<p>僅需要在tensor之後加上轉換的型態即可。</p>
<div class="highlight"><pre><span></span><span class="n">tensor_a_long</span> <span class="o">=</span> <span class="n">tensor_a</span><span class="o">.</span><span class="n">long</span><span class="p">()</span> <span class="c1"># 將tensor_a轉換為long資料型態。</span>
<span class="n">tensor_a_float</span> <span class="o">=</span> <span class="n">tensor_a</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># 將tensor_a轉換為float資料型態。</span>
</pre></div>


<h2>與其他常用套件之轉換</h2>
<div class="highlight"><pre><span></span><span class="n">tensor_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_element</span><span class="p">)</span> <span class="c1"># numpy -&gt; torch</span>
<span class="n">np_a</span> <span class="o">=</span> <span class="n">tensor_a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># torch -&gt; numpy</span>
</pre></div>


<hr>
<h1>常會使用到的Module</h1>
<p>通常在Pytorch時，常會使用到下列的Module</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
</pre></div>


<ul>
<li><strong>torch</strong> : Pytorch基本的套件</li>
<li><strong>torch.nn</strong> : 定義了基本的Layer元件 (例如: Linear)，在建構模型時會使用到。(請見<a href="#如何建立一個Network">5. 如何建立一個Network。</a>)</li>
<li><strong>torch.nn.functional</strong> : 定義了卷積、Activation Function等。</li>
<li><strong>torch.optim</strong> : 定義了許多常見的optimizer.（請見<a href="#訓練的Pipeline">7.訓練的Pipeline</a>)</li>
<li><strong>torch.utils.data</strong> : 定義了Dataset及DataLoader等資料相關Class (請見<a href="#如何建立訓練資料集">6. 如何建立訓練資料集</a>)</li>
<li><strong>torch.utils.tensorboard</strong> : 定義了與Tensorboard互動相關的Class (請見<a href="#視覺化工具-TensorBoard">8. 視覺化工具-TensorBoard</a>)</li>
</ul>
<hr>
<h1>建立一個Network</h1>
<p>通常透過Pytorch 建立一個Network時，我們習慣透過定義<strong>Python的Class</strong> 來建構我們的Network. 這一個Python Class必須具備下列特性:</p>
<ol>
<li>必須繼承 <code>torch.nn.Module</code>，這樣才能使用Pytorch內建的各種function，並且與其他Pytorch元件進行互動。</li>
<li>
<p>繼承 <code>torch.nn.Module</code>後，會需要Override一些特定的Method: </p>
<ul>
<li><strong>__init__()</strong>: </li>
</ul>
<p>定義在Initial此Class(Network)時需要初始化的元件。基本上在Network中需要使用到的Layer、Hyperparameter都需要在這邊先行定義。
+ <strong>forward()</strong>: 
  - 透過Override forward這個Method來定義此Network的Forward Propagation方式。 </p>
<ul>
<li>值得注意的是<code>forward()</code> 在Override以後，往後透過可以直接透過call model來進行forward(). (請看下方範例)</li>
</ul>
</li>
</ol>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyOwnNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">my_own_net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> <span class="c1">#初始化 nn.Module class</span>

        <span class="c1"># 以下按照需求定義Layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">384</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">MyOwnNet</span><span class="p">()</span>
    <span class="n">test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">768</span><span class="p">))</span>
    <span class="n">test_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">test_input</span><span class="p">)</span> <span class="c1"># 直接呼叫instance，將會自動執行forward()的function.</span>
</pre></div>


<hr>
<h1>建立訓練資料集</h1>
<p>在定義好模型架構後，接著需要處理資料的部分。</p>
<p>當然在提供訓練資料時，我們也可以單純透過迴圈的方式自行提取，但是透過Pytorch的資料集，我們不需要再特別去處理「Batch size」或是「Shuffle」的問題。</p>
<p>這裡記錄了兩種Pytorch 內建的Module提供我們實作並且改寫:
1. Dataset
2. DataLoader</p>
<h2>Dataset</h2>
<p>實作時，與上節建立Network相同，需要先定義一個Python Class來繼承 <code>torch.utils.data.Dataset</code>，並且要Override以下Methods:</p>
<ul>
<li><strong>__init__(self)</strong>: 初始化instance時需要進行的動作，通常會在這個地方載入資料集、或是進行前處理。</li>
<li><strong>_getitem(self, index)__</strong>: 定義使用idx去query元素時要進行的動作。 (通常直接回傳第index筆資料)</li>
<li>
<p><strong>_len(self)__</strong>: 定義使用len()去取得instance元素數量時要進行的動作。 （通常直接回傳資料筆數)</p>
<p>:::python
class OwnDataset(Dataset):
    def <strong>init</strong>(self, file_path):
        super(OwnDataset, self).<strong>init</strong>()
        self.data = pickle.load(open(file_path, "rb")) # 讀取資料</p>
<div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">__len__</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">len</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="k">data</span><span class="p">)</span>

<span class="n">def</span> <span class="n">__getitem__</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="k">return</span> <span class="err">{</span><span class="ss">&quot;x&quot;</span><span class="p">:</span> <span class="k">self</span><span class="p">.</span><span class="k">data</span><span class="p">[</span><span class="ss">&quot;feature&quot;</span><span class="p">],</span> <span class="ss">&quot;y&quot;</span><span class="p">:</span> <span class="k">self</span><span class="p">.</span><span class="k">data</span><span class="p">[</span><span class="ss">&quot;label&quot;</span><span class="p">]</span><span class="err">}</span>
</pre></div>


<p>if <strong>name</strong> == "<strong>main</strong>":
    dataset = OwnDataset("./data/test.pickle") #Initial an instance.</p>
<div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span> <span class="o">#</span> <span class="k">Call</span> <span class="n">__len__</span><span class="p">()</span>
<span class="n">a_example</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">#</span> <span class="k">Call</span> <span class="n">__getitem__</span><span class="p">()</span>

<span class="n">feature</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">a_example</span><span class="p">[</span><span class="ss">&quot;x&quot;</span><span class="p">],</span> <span class="n">a_example</span><span class="p">[</span><span class="ss">&quot;y&quot;</span><span class="p">]</span>
</pre></div>


</li>
</ul>
<p>從範例中可以看到使用Dataset的好處在於先行定義好回傳資料的格式、以及如何取用資料。 進行訓練時就不需要再重複的撰寫取用資料的程式。</p>
<p>也可以在Dataset中加入一個 <code>type</code>變數來切換要回傳 training、evaluation、testing set. 並且針對傳入的型態不同來進行資料的Sample。</p>
<h2>DataLoader</h2>
<p>除此之外，再進行訓練時常會需要動態的調整 <code>batch_size</code>以及需要打亂資料(Shuffle)，如果自行撰寫Function的話，常會被index搞得昏頭轉向。 有時多一個idx就會造成 out of range的錯誤。</p>
<p>此時如果你有按照上述的格式定義好一個 <code>Dataset</code>，那麼以上任務都不用擔心，我們可以透過 <code>DataLoader</code>直接處理好。</p>
<p><code>DataLoader</code>具有幾個參數:
+ dataset: 放入我們剛剛創建的OwnDataset Instance.
+ batch_size: 一個batch要包含多少資料筆數。
+ shuffle: 是否對資料進行隨機調整。
+ num_workers: 透過Multi-Process來加速資料的取用，避免訓練時速度被IO給限制。（不建議使用在GPU環境)
+ pin_memory: 在使用GPU時，啟用此屬性能提升訓練速度。</p>
<p>有關<code>num_workers</code>, <code>pin_memory</code>的探討，建議可以參考<a href="https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading">官方文件</a></p>
<div class="highlight"><pre><span></span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">))</span> <span class="c1">#回傳當前共有幾個batch，可以直接用這個數值來作為Step.</span>

<span class="n">data_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span> <span class="c1"># 透過這種方式來取用資料。</span>

<span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span> <span class="c1"># 也可以透過For loop來取用資料。</span>
    <span class="n">some_train_step</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>


<p>在定義完 <code>Dataset</code>後，透過 <code>DataLoader</code>來對資料進行訓練前的處理，接著就能按照需求去取得資料。相當的方便且簡潔。</p>
<hr>
<h1>訓練的Pipeline</h1>
<p>個人認為建構Model的Pipeline大略如下:
1. 定義Model.
2. 定義Dataset.
3. 定義Loss以及Optimizer.
4. 進行訓練.</p>
<p>其中第一點以及第二點請參考本文前段。</p>
<h2>定義Loss及Optimizer</h2>
<p>在 <code>torch.nn</code> 以及 <code>torch.nn.Functional</code>中定義了許多不同的Loss Function，可以根據需求自行選擇. 以下範例以分類問題的CrossEntropy為例:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># Init an instance.</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span> 
<span class="c1"># 建立一個optimizer來優化 model 的所有&quot;可訓練參數&quot;</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>


<p>首先，必須先建立計算Loss以及Optimizer的Instance。</p>
<p>在建立Optimizer時會需要設定優化的對象，通常會直接放<code>model.parameters()</code>，代表<code>model</code>中所有可訓練的參數。而不同的Optimizer(SGD, Adam, ...)會有不同的參數要進行設定。</p>
<h2>進行訓練</h2>
<div class="highlight"><pre><span></span><span class="n">feature</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">next</span><span class="p">()</span> <span class="c1">#透過前面提到的iterator取得一個batch的資料。</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 將訓練資料送入model中進行forward propagation。</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># 回傳當前Forward結果與真實Label的Loss</span>

<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># 先清空當前的梯度值</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># 進行Backward Propagation</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 針對Backward Propagation所得到的梯度調整參數。</span>
</pre></div>


<p>接著直接呼叫<code>model(x)</code>如同上節所說，就是直接將<code>x</code>送入<code>model</code>中進行Forward Propagation。 得到的結果可以直接與真實label送到剛剛建立的Loss Instance計算Loss.</p>
<p>在計算完Loss後，我們就能直接使用 <code>loss.backward()</code>來取得Loss對所有參數的梯度。 在Pytorch中，我們只有定義Forward的方式，而Backward Propagation只需要透過短短一行即可得到。</p>
<p>取得每一個參數的梯度以後，就能呼叫剛剛定義的<code>optimizer.step()</code>來進行參數調整。</p>
<p>以上就是一次的訓練迭代:
<strong>Forward propagation -&gt; 計算Loss -&gt; Backward propagation -&gt; Optimize (根據梯度調整Weight.)</strong></p>
<p>實際訓練時可根據需求來不斷從Data Iterator中取得資料，重複上述迭代進行訓練，也因為會有不斷的迭代，所以記得使用<code>optimizer.zero_grad()</code>來清空上一次的梯度。</p>
<p>另外，在Pytorch中的Tensor都會有<code>requires_grad</code>的屬性，如果啟用的話會自動追蹤計算圖，方便直接呼叫<code>backward()</code>，如果不希望啟用的話，可以透過下列方法解除:</p>
<div class="highlight"><pre><span></span><span class="c1"># Method 1</span>
<span class="n">tensor_nograd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Method 2</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># 以下做的事情都不會取得梯度。</span>
    <span class="c1"># Your Code.</span>
</pre></div>


<hr>
<h1>視覺化工具-TensorBoard</h1>
<h2>基本使用</h2>
<p>在訓練的過程中，我們需要觀察Loss或是Accuracy來確認訓練的效果，雖然可以透過Print Log的方式來顯示，但其實透過有更好的工具能夠協助視覺化。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="n">LOGDIR</span> <span class="o">=</span> <span class="s2">&quot;./logs/&quot;</span> <span class="c1"># Define 資料要被寫入的位置</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">LOGDIR</span><span class="p">)</span>

<span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;Loss/train&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;Loss/test&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;Accuracy/train&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;Accuracy/test&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(),</span> <span class="n">n_iter</span><span class="p">)</span>
</pre></div>


<p>也就是在定義了一個writer後，可以透過<code>writer.add_scalar</code>的方式將想要觀測的值記錄下來，同時可以分門別類的設定標籤、Step或是Epoch數目。 除了<code>add_scalar</code>外，還有許多如<code>add_image</code>、<code>add_graph</code>的方法可以使用。</p>
<p>寫入資料後，執行tensorboard即可在LocalHost的瀏覽器觀察結果: </p>
<div class="highlight"><pre><span></span>pip install tensorboard
tensorboard --logdir<span class="o">=</span><span class="s2">&quot;./logs&quot;</span>
</pre></div>


<p><img alt="" src="https://pytorch.org/docs/stable/_images/hier_tags.png"> </p>
<p><a href="https://pytorch.org/docs/stable/tensorboard.html">圖片來源</a></p>
<h2>Remote Server</h2>
<p>另外在進行機器學習時，常常會需要使用到遠端主機的GPU，紀錄一下如何在Localhost查看遠端機器的訓練狀態。 首先還是一樣要在訓練過程中透過<code>SummaryWriter</code>將log寫入。</p>
<p>接著透過 SSH連線將本地端的一個Port 與 遠端機器的特定Port綁定在一起，首先在本地端執行:</p>
<div class="highlight"><pre><span></span>ssh -L <span class="m">16001</span>:127.0.0.1:16001 username@server_ip
</pre></div>


<p>透過特定Port與遠端主機連線。</p>
<p>接著在 <strong>遠端主機</strong>執行</p>
<div class="highlight"><pre><span></span>tensorboard --logdir<span class="o">=</span><span class="s2">&quot;./logs&quot;</span> --port<span class="o">=</span><span class="m">16001</span>
</pre></div>


<p>同樣的啟動指令，只是規定要在剛剛設定Port上啟動服務。</p>
<p>如此一來就能在自己的主機上查看遠端Server的訓練狀況了。</p>
<hr>
<h1>儲存、載入Model</h1>
<p>在訓練完模型後，需要將模型儲存下來，方便日後驗證或使用。
Pytorch 提供了兩種儲存方法: <code>完整模型</code>以及 <code>State_dict</code></p>
<h2>完整模型:</h2>
<p>官方較不推薦這種方式，由於是透過<code>pickle</code>的方式進行儲存，很可能會遭遇意料之外的問題。</p>
<h3>Save</h3>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>


<h3>Load</h3>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>


<p>在Pytorch的model中，可以透過 <code>model.train()</code>以及<code>model.eval()</code>來切換不同模式，使用<code>model.eval()</code>會將dropout layer 以及 batch_normalization 切換成驗證模式，避免在Inference的過程中造成結果不一致。</p>
<h2>State Dict</h2>
<p>State Dictionary 則是透過 <code>Python的Dictionary</code>來儲存每一層的內容以及權重。如果要查看的話可以透過<code>model.state_dict()</code>來取得。</p>
<h3>Save</h3>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>


<h3>Load</h3>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyOwnNet</span><span class="p">()</span> <span class="c1"># 要先建立相同的Class Instance.</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>


<hr>
<h1>使用GPU</h1>
<p>在上述的內容完成後，基本上已經可以建立一個簡易的Neural Network了，接下來紀錄如何將快速的將資料從CPU訓練切換為GPU.</p>
<p>首先要先確定自己的Pytorch是有安裝到CUDA版本。
可以透過下列指令確認:</p>
<div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
</pre></div>


<p>如果是True則代表有成功偵測到GPU，若為False則可能是設定錯誤！</p>
<p>接著要建立一個device變數:</p>
<div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>


<p>接著就是將自己的Model以及需要送進Model的Input都轉換為GPU模式.</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 以下正常進行使用</span>
</pre></div>


<p>只要加上短短一行指令即可切換為GPU模式，此時如果在print這些tensor，可以發現數值不變，但是後面多了一個"cuda:n"屬性，這就代表Tensor已經被送到GPU去了。</p>
<hr>
<h1>後記</h1>
<p>在學習Pytorch的過程中，很多教材都是語法居多，透過實際進行任務的方式教學，但我在過程中對於許多Component都似懂非懂，現在稍微釐清後，記錄下來，希望如果是想學習Pytorch的入門者，看完這篇文章可以了解一些基本觀念，在看網路上的Tutorial或是Track別人的Code時，能夠不再霧煞煞～</p>
    
                    <p class="blog-content__tags">
                        <span>Post Tags</span>
    
                        <span class="blog-content__tag-list">
                             <a href="#0">Pytorch</a>
                        </span>
    
                    </p>
    
                    <div class="blog-content__pagenav">
                        <div class="blog-content__nav">


















                            <div class="blog-content__prev">
                                <a href="https://minglunwu.github.io/notes/2020/20200416.html" rel="prev">
                                    <span>Previous Post</span>
                                    Pytorch Lightning 入門筆記
                                </a>
                            </div>
                            <div class="blog-content__next">
                                <a href="https://minglunwu.github.io/notes/2020/20200318.html" rel="next">
                                    <span>Next Post</span>
                                    安裝 Miniconda 以及 Pytorch
                                </a>
                            </div>
                        </div>
    
                        <div class="blog-content__all">
                            <a href="https://minglunwu.github.io/archives.html" class="btn btn--primary">
                                View All Post
                            </a>
                        </div>
                    </div>
    
                </div><!-- end blog-content__main -->
            </div> <!-- end blog-content -->
    
        </article>
            <!-- footer
    ================================================== -->
    <footer>
        <div class="row">
            <div class="col-full">

                <div class="footer-logo">
                    <a class="footer-site-logo" href="#0"><img src="https://minglunwu.github.io/theme/images/logo.png" alt="Homepage"></a>
                </div>
                <ul class="footer-social">
                    <li>
                        <a href="https://www.facebook.com/zebra52000" target="_blank"><i class="im im-facebook" aria-hidden="true"></i><span>Facebook</span></a>
                    </li>
                    <li>
                        <a href="https://medium.com/@allen6997535" target="_blank"><i class="im im-book" aria-hidden="true"></i><span>Medium</span></a>
                    </li>
                    <li>
                        <a href="https://github.com/MingLunWu" target="_blank"><i class="im im-github" aria-hidden="true"></i><span>Github</span></a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/allen-ming-lun-wu-637020142/" target="_blank"><i class="im im-linkedin" aria-hidden="true"></i><span>LinkedIn</span></a>
                    </li>
                    <li>
                        <a href="https://www.instagram.com/whoisfater0724/" target="_blank"><i class="im im-instagram" aria-hidden="true"></i><span>Instagram</span></a>
                    </li>
                </ul>
                    
            </div>
        </div>

        <div class="row footer-bottom">

            <div class="col-twelve">
                <div class="copyright">
                    <span>© Copyright Hola 2017</span> 
                    <span>Design by <a href="https://www.styleshout.com/">styleshout</a></span>	
                </div>

                <div class="go-top">
                <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
                </div>
            </div>

        </div> <!-- end footer-bottom -->

    </footer> <!-- end footer -->
    <!-- Java Script
        ================================================== -->
        <script src="https://minglunwu.github.io/theme/js/jquery-3.2.1.min.js"></script>
        <script src="https://minglunwu.github.io/theme/js/plugins.js"></script>
        <script src="https://minglunwu.github.io/theme/js/main.js"></script>

    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-161863471-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-161863471-1');
    </script>
    
</body>