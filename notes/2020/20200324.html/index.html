<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Byte and Ink"><meta property="og:type" content="article"><meta property="og:image" content="https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80"><meta property="twitter:image" content="https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80"><meta name=title content="從零開始 - Pytorch 入門懶人包"><meta property="og:title" content="從零開始 - Pytorch 入門懶人包"><meta property="twitter:title" content="從零開始 - Pytorch 入門懶人包"><meta name=description content><meta property="og:description" content><meta property="twitter:description" content><meta property="twitter:card" content="研究所時有花時間去了解Neural Network的概念，但卻一直沒有機會進行實作，最近有機會可以從頭開始學習Pytorch，把學習的過程整理記錄下來，希望想要快速上手Pytorch的人，可以透過這篇文章快速入門！"><meta name=keyword content="吳明倫, MingLun, minglunwu"><link rel="shortcut icon" href=/img/favicon.ico><title>從零開始 - Pytorch 入門懶人包 | Byte and Ink</title><link rel=canonical href=/notes/2020/20200324.html/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script>
<script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NC508K3RBY"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NC508K3RBY",{anonymize_ip:!1})}</script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/>Byte and Ink</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/obsidian/>obsidian</a></li><li><a href=/categories/reading-with-ml/>reading-with-ml</a></li><li><a href=/categories/weekly-reflection/>weekly-reflection</a></li><li><a href=/archive/>ARCHIVE</a></li><li><a href=/about/>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.unsplash.com/photo-1502951682449-e5b93545d46e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1566&q=80)}.utterances{max-width:100%}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/tool title=Tool>Tool</a></div><h1>從零開始 - Pytorch 入門懶人包</h1><h2 class=subheading></h2><span class=meta>Posted by
MingLun Allen Wu
on
Tuesday, March 24, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=前言>前言</h1><p>研究所時有花時間去了解Neural Network的概念，但卻一直沒有機會進行實作，最近有機會可以從頭開始學習Pytorch，把學習的過程整理記錄下來，希望想要快速上手Pytorch的人，可以透過這篇文章快速入門！</p><h1 id=tensor的基本使用格式轉換>Tensor的基本使用、格式轉換</h1><h2 id=建立tensor>建立Tensor</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>a <span style=color:#ff79c6>=</span> [<span style=color:#bd93f9>1</span>,<span style=color:#bd93f9>2</span>,<span style=color:#bd93f9>3</span>]
</span></span><span style=display:flex><span>tensor_a <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>tensor(a)
</span></span></code></pre></div><h2 id=tensor-的維度轉換>Tensor 的維度轉換</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tensor_reshape <span style=color:#ff79c6>=</span> tensor_a<span style=color:#ff79c6>.</span>view(<span style=color:#bd93f9>1</span>,<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>)
</span></span></code></pre></div><h2 id=tensor-中的元素型態轉換>Tensor 中的元素型態轉換</h2><p>僅需要在tensor之後加上轉換的型態即可。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tensor_a_long <span style=color:#ff79c6>=</span> tensor_a<span style=color:#ff79c6>.</span>long() <span style=color:#6272a4># 將tensor_a轉換為long資料型態。</span>
</span></span><span style=display:flex><span>tensor_a_float <span style=color:#ff79c6>=</span> tensor_a<span style=color:#ff79c6>.</span>float() <span style=color:#6272a4># 將tensor_a轉換為float資料型態。</span>
</span></span></code></pre></div><h2 id=與其他常用套件之轉換>與其他常用套件之轉換</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tensor_b <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>from_numpy(np_element) <span style=color:#6272a4># numpy -&gt; torch</span>
</span></span><span style=display:flex><span>np_a <span style=color:#ff79c6>=</span> tensor_a<span style=color:#ff79c6>.</span>numpy() <span style=color:#6272a4># torch -&gt; numpy</span>
</span></span></code></pre></div><hr><h1 id=常會使用到的module>常會使用到的Module</h1><p>通常在 <code>Pytorch</code> 時，常會使用到下列的 Module</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> torch
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.nn <span style=color:#ff79c6>as</span> nn
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.nn.functional <span style=color:#ff79c6>as</span> F
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.optim <span style=color:#ff79c6>as</span> optim
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> torch.utils.data <span style=color:#ff79c6>import</span> Dataset, DataLoader
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> torch.utils.tensorboard <span style=color:#ff79c6>import</span> SummaryWriter
</span></span></code></pre></div><ul><li><strong>torch</strong> : <code>Pytorch</code> 基本的套件</li><li><strong>torch.nn</strong> : 定義了基本的 Layer 元件 (例如: Linear)，在建構模型時會使用到。(請見<a href=#%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E4%B8%80%E5%80%8BNetwork>5. 如何建立一個Network。</a>)</li><li><strong>torch.nn.functional</strong> : 定義了卷積、Activation Function 等。</li><li><strong>torch.optim</strong> : 定義了許多常見的 optimizer.（請見<a href=#%E8%A8%93%E7%B7%B4%E7%9A%84Pipeline>7.訓練的Pipeline</a>)</li><li><strong>torch.utils.data</strong> : 定義了 Dataset 及 DataLoader 等資料相關 Class (請見<a href=#%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E8%A8%93%E7%B7%B4%E8%B3%87%E6%96%99%E9%9B%86>6. 如何建立訓練資料集</a>)</li><li><strong>torch.utils.tensorboard</strong> : 定義了與 Tensorboard 互動相關的 Class (請見<a href=#%E8%A6%96%E8%A6%BA%E5%8C%96%E5%B7%A5%E5%85%B7-TensorBoard>8. 視覺化工具-TensorBoard</a>)</li></ul><hr><h1 id=建立一個network>建立一個Network</h1><p>通常透過 <code>Pytorch</code> 建立一個 Network 時，我們習慣透過定義<strong>Python 的 Class</strong> 來建構我們的 Network. 這一個Python Class 必須具備下列特性:</p><ol><li><p>必須繼承 <code>torch.nn.Module</code>，這樣才能使用 Pytorch 內建的各種 function，並且與其他 Pytorch 元件進行互動。</p></li><li><p>繼承 <code>torch.nn.Module</code>後，會需要 Override 一些特定的 Method:</p><ul><li><strong>_<em>init</em>_()</strong>:</li></ul><p>定義在 Initial 此 Class(Network) 時需要初始化的元件。基本上在 Network 中需要使用到的 Layer、Hyperparameter 都需要在這邊先行定義。</p><ul><li><strong>forward()</strong>:<ul><li><p>透過 Override forward 這個 Method 來定義此 Network 的 Forward Propagation 方式。</p></li><li><p>值得注意的是 <code>forward()</code> 在 Override 以後，往後透過可以直接透過 call model 來進行 forward(). (請看下方範例)</p></li></ul></li></ul></li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>MyOwnNet</span>(nn<span style=color:#ff79c6>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> __init__(self):
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>super</span>(my_own_net, self)<span style=color:#ff79c6>.</span>__init__() <span style=color:#6272a4>#初始化 nn.Module class</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 以下按照需求定義Layer.</span>
</span></span><span style=display:flex><span>        self<span style=color:#ff79c6>.</span>ln <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Linear(<span style=color:#bd93f9>768</span>, <span style=color:#bd93f9>384</span>)
</span></span><span style=display:flex><span>        self<span style=color:#ff79c6>.</span>ln_2 <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Linear(<span style=color:#bd93f9>384</span>, <span style=color:#bd93f9>10</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>forward</span>(self, x):
</span></span><span style=display:flex><span>        outputs <span style=color:#ff79c6>=</span> self<span style=color:#ff79c6>.</span>ln(x)
</span></span><span style=display:flex><span>        outputs <span style=color:#ff79c6>=</span> self<span style=color:#ff79c6>.</span>ln_2(outputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> __name__ <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    net <span style=color:#ff79c6>=</span> MyOwnNet()
</span></span><span style=display:flex><span>    test <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>list</span>(<span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>768</span>))
</span></span><span style=display:flex><span>    test_input <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>tensor(test)
</span></span><span style=display:flex><span>    outputs <span style=color:#ff79c6>=</span> net(test_input) <span style=color:#6272a4># 直接呼叫instance，將會自動執行forward()的function.</span>
</span></span></code></pre></div><hr><h1 id=建立訓練資料集>建立訓練資料集</h1><p>在定義好模型架構後，接著需要處理資料的部分。</p><p>當然在提供訓練資料時，我們也可以單純透過迴圈的方式自行提取，但是透過 <code>Pytorch</code> 的資料集，我們不需要再特別去處理「Batch size」或是「Shuffle」的問題。</p><p>這裡記錄了兩種 <code>Pytorch</code> 內建的 Module 提供我們實作並且改寫:</p><ol><li>Dataset</li><li>DataLoader</li></ol><h2 id=dataset>Dataset</h2><p>實作時，與上節建立 Network 相同，需要先定義一個 Python Class 來繼承 <code>torch.utils.data.Dataset</code>，並且要Override 以下 Methods:</p><ul><li><strong>_<em>init</em>_(self)</strong>: 初始化 instance 時需要進行的動作，通常會在這個地方載入資料集、或是進行前處理。</li><li><strong>_getitem(self, index)__</strong>: 定義使用 idx 去 query 元素時要進行的動作。 (通常直接回傳第 index 筆資料)</li><li><strong>_len(self)__</strong>: 定義使用 len() 去取得 instance 元素數量時要進行的動作。 （通常直接回傳資料筆數)</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>OwnDataset</span>(Dataset):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> __init__(self, file_path):
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>super</span>(OwnDataset, self)<span style=color:#ff79c6>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#ff79c6>.</span>data <span style=color:#ff79c6>=</span> pickle<span style=color:#ff79c6>.</span>load(<span style=color:#8be9fd;font-style:italic>open</span>(file_path, <span style=color:#f1fa8c>&#34;rb&#34;</span>)) <span style=color:#6272a4># 讀取資料</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> __len__(self):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> <span style=color:#8be9fd;font-style:italic>len</span>(self<span style=color:#ff79c6>.</span>data)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> __getitem__(self, idx):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> {<span style=color:#f1fa8c>&#34;x&#34;</span>: self<span style=color:#ff79c6>.</span>data[<span style=color:#f1fa8c>&#34;feature&#34;</span>], <span style=color:#f1fa8c>&#34;y&#34;</span>: self<span style=color:#ff79c6>.</span>data[<span style=color:#f1fa8c>&#34;label&#34;</span>]}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> __name__ <span style=color:#ff79c6>==</span> <span style=color:#f1fa8c>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    dataset <span style=color:#ff79c6>=</span> OwnDataset(<span style=color:#f1fa8c>&#34;./data/test.pickle&#34;</span>) <span style=color:#6272a4>#Initial an instance.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#8be9fd;font-style:italic>len</span>(dataset)) <span style=color:#6272a4># Call __len__()</span>
</span></span><span style=display:flex><span>    a_example <span style=color:#ff79c6>=</span> dataset[<span style=color:#bd93f9>0</span>] <span style=color:#6272a4># Call __getitem__()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    feature, label <span style=color:#ff79c6>=</span> a_example[<span style=color:#f1fa8c>&#34;x&#34;</span>], a_example[<span style=color:#f1fa8c>&#34;y&#34;</span>]
</span></span></code></pre></div><p>從範例中可以看到使用 Dataset 的好處在於先行定義好回傳資料的格式、以及如何取用資料。進行訓練時就不需要再重複的撰寫取用資料的程式。</p><p>也可以在Dataset中加入一個 <code>type</code> 變數來切換要回傳 training、evaluation、testing set. 並且針對傳入的型態不同來進行資料的Sample。</p><h2 id=dataloader>DataLoader</h2><p>除此之外，再進行訓練時常會需要動態的調整 <code>batch_size</code> 以及需要打亂資料(Shuffle)，如果自行撰寫 Function 的話，常會被 index 搞得昏頭轉向。 有時多一個 idx 就會造成 out of range 的錯誤。</p><p>此時如果你有按照上述的格式定義好一個 <code>Dataset</code>，那麼以上任務都不用擔心，我們可以透過 <code>DataLoader</code> 直接處理好。</p><p><code>DataLoader</code> 具有幾個參數:</p><ul><li>dataset: 放入我們剛剛創建的 OwnDataset Instance.</li><li>batch_size: 一個 batch 要包含多少資料筆數。</li><li>shuffle: 是否對資料進行隨機調整。</li><li>num_workers: 透過 Multi-Process 來加速資料的取用，避免訓練時速度被 IO 給限制。（不建議使用在GPU環境)</li><li>pin_memory: 在使用 GPU 時，啟用此屬性能提升訓練速度。</li></ul><p>有關 <code>num_workers</code>, <code>pin_memory</code> 的探討，建議可以參考<a href=https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading>官方文件</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data_loader <span style=color:#ff79c6>=</span> DataLoader(dataset<span style=color:#ff79c6>=</span> dataset, batch_size<span style=color:#ff79c6>=</span> <span style=color:#bd93f9>4</span>, shuffle<span style=color:#ff79c6>=</span> <span style=color:#ff79c6>True</span>, num_workers<span style=color:#ff79c6>=</span> <span style=color:#bd93f9>2</span>, pin_memory<span style=color:#ff79c6>=</span> <span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#8be9fd;font-style:italic>len</span>(data_loader)) <span style=color:#6272a4>#回傳當前共有幾個batch，可以直接用這個數值來作為Step.</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_iter <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>iter</span>(data_loader)
</span></span><span style=display:flex><span>x, y <span style=color:#ff79c6>=</span> data_iter<span style=color:#ff79c6>.</span>next() <span style=color:#6272a4># 透過這種方式來取用資料。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> (x,y) <span style=color:#ff79c6>in</span> data_iter: <span style=color:#6272a4># 也可以透過For loop來取用資料。</span>
</span></span><span style=display:flex><span>    some_train_step(x)
</span></span></code></pre></div><p>在定義完 <code>Dataset</code> 後，透過 <code>DataLoader</code> 來對資料進行訓練前的處理，接著就能按照需求去取得資料。相當的方便且簡潔。</p><hr><h1 id=訓練的pipeline>訓練的Pipeline</h1><p>個人認為建構 Model 的 Pipeline 大略如下:</p><ol><li>定義 Model.</li><li>定義 Dataset.</li><li>定義 Loss 以及 Optimizer.</li><li>進行訓練.</li></ol><p>其中第一點以及第二點請參考本文前段。</p><h2 id=定義loss及optimizer>定義Loss及Optimizer</h2><p>在 <code>torch.nn</code> 以及 <code>torch.nn.Functional</code> 中定義了許多不同的 Loss Function，可以根據需求自行選擇. 以下範例以分類問題的 CrossEntropy 為例:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.nn <span style=color:#ff79c6>as</span> nn
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.nn.functional <span style=color:#ff79c6>as</span> F
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch.optim <span style=color:#ff79c6>as</span> optim
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># Init an instance.</span>
</span></span><span style=display:flex><span>criterion <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>CrossEntropyLoss() 
</span></span><span style=display:flex><span><span style=color:#6272a4># 建立一個optimizer來優化 model 的所有&#34;可訓練參數&#34;</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#ff79c6>=</span> optim<span style=color:#ff79c6>.</span>Adam(model<span style=color:#ff79c6>.</span>parameters(), lr<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1e-5</span>)
</span></span></code></pre></div><p>首先，必須先建立計算 Loss 以及 Optimizer 的 Instance。</p><p>在建立 Optimizer 時會需要設定優化的對象，通常會直接放 <code>model.parameters()</code>，代表 <code>model</code> 中所有可訓練的參數。而不同的 Optimizer(SGD, Adam, &mldr;) 會有不同的參數要進行設定。</p><h2 id=進行訓練>進行訓練</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>feature, label <span style=color:#ff79c6>=</span> data_iter<span style=color:#ff79c6>.</span>next() <span style=color:#6272a4>#透過前面提到的iterator取得一個batch的資料。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>outputs <span style=color:#ff79c6>=</span> model(x) <span style=color:#6272a4># 將訓練資料送入model中進行forward propagation。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>loss <span style=color:#ff79c6>=</span> criterion(outputs, y) <span style=color:#6272a4># 回傳當前Forward結果與真實Label的Loss</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>optimizer<span style=color:#ff79c6>.</span>zero_grad() <span style=color:#6272a4># 先清空當前的梯度值</span>
</span></span><span style=display:flex><span>loss<span style=color:#ff79c6>.</span>backward() <span style=color:#6272a4># 進行Backward Propagation</span>
</span></span><span style=display:flex><span>optimizer<span style=color:#ff79c6>.</span>step() <span style=color:#6272a4># 針對Backward Propagation所得到的梯度調整參數。</span>
</span></span></code></pre></div><p>接著直接呼叫 <code>model(x)</code> 如同上節所說，就是直接將 <code>x</code> 送入 <code>model</code> 中進行 Forward Propagation。 得到的結果可以直接與真實 label 送到剛剛建立的 Loss Instance 計算 Loss.</p><p>在計算完Loss後，我們就能直接使用 <code>loss.backward()</code> 來取得 Loss 對所有參數的梯度。 在 <code>Pytorch</code> 中，我們只有定義 Forward 的方式，而 Backward Propagation 只需要透過短短一行即可得到。</p><p>取得每一個參數的梯度以後，就能呼叫剛剛定義的 <code>optimizer.step()</code> 來進行參數調整。</p><p>以上就是一次的訓練迭代:
<strong>Forward propagation -> 計算Loss -> Backward propagation -> Optimize (根據梯度調整Weight.)</strong></p><p>實際訓練時可根據需求來不斷從 Data Iterator 中取得資料，重複上述迭代進行訓練，也因為會有不斷的迭代，所以記得使用 <code>optimizer.zero_grad()</code> 來清空上一次的梯度。</p><p>另外，在 <code>Pytorch</code> 中的 <code>Tensor</code> 都會有 <code>requires_grad</code> 的屬性，如果啟用的話會自動追蹤計算圖，方便直接呼叫<code>backward()</code>，如果不希望啟用的話，可以透過下列方法解除:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># Method 1</span>
</span></span><span style=display:flex><span>tensor_nograd <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>tensor([<span style=color:#bd93f9>1</span>,<span style=color:#bd93f9>2</span>,<span style=color:#bd93f9>3</span>], requires_grad<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># Method 2</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>with</span> torch<span style=color:#ff79c6>.</span>no_grad(): <span style=color:#6272a4># 以下做的事情都不會取得梯度。</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># Your Code.</span>
</span></span></code></pre></div><hr><h1 id=視覺化工具-tensorboard>視覺化工具-TensorBoard</h1><h2 id=基本使用>基本使用</h2><p>在訓練的過程中，我們需要觀察 Loss 或是 Accuracy 來確認訓練的效果，雖然可以透過 Print Log 的方式來顯示，但其實透過有更好的工具能夠協助視覺化。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> torch.utils.tensorboard <span style=color:#ff79c6>import</span> SummaryWriter
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>LOGDIR <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;./logs/&#34;</span> <span style=color:#6272a4># Define 資料要被寫入的位置</span>
</span></span><span style=display:flex><span>writer <span style=color:#ff79c6>=</span> SummaryWriter(LOGDIR)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> n_iter <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>100</span>):
</span></span><span style=display:flex><span>    writer<span style=color:#ff79c6>.</span>add_scalar(<span style=color:#f1fa8c>&#39;Loss/train&#39;</span>, np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>random(), n_iter)
</span></span><span style=display:flex><span>    writer<span style=color:#ff79c6>.</span>add_scalar(<span style=color:#f1fa8c>&#39;Loss/test&#39;</span>, np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>random(), n_iter)
</span></span><span style=display:flex><span>    writer<span style=color:#ff79c6>.</span>add_scalar(<span style=color:#f1fa8c>&#39;Accuracy/train&#39;</span>, np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>random(), n_iter)
</span></span><span style=display:flex><span>    writer<span style=color:#ff79c6>.</span>add_scalar(<span style=color:#f1fa8c>&#39;Accuracy/test&#39;</span>, np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>random(), n_iter)
</span></span></code></pre></div><p>也就是在定義了一個 writer 後，可以透過 <code>writer.add_scalar</code> 的方式將想要觀測的值記錄下來，同時可以分門別類的設定標籤、Step 或是 Epoch 數目。 除了<code>add_scalar</code> 外，還有許多如 <code>add_image</code>、<code>add_graph</code> 的方法可以使用。</p><p>寫入資料後，執行 tensorboard 即可在 LocalHost 的瀏覽器觀察結果:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>pip install tensorboard
</span></span><span style=display:flex><span>tensorboard --logdir<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;./logs&#34;</span>
</span></span></code></pre></div><p><img src=https://pytorch.org/docs/stable/_images/hier_tags.png alt></p><p><a href=https://pytorch.org/docs/stable/tensorboard.html>圖片來源</a></p><h2 id=remote-server>Remote Server</h2><p>另外在進行機器學習時，常常會需要使用到遠端主機的 GPU，紀錄一下如何在 Localhost 查看遠端機器的訓練狀態。
首先還是一樣要在訓練過程中透過 <code>SummaryWriter</code> 將 log 寫入。</p><p>接著透過 SSH連線將本地端的一個 Port 與遠端機器的特定 Port 綁定在一起，首先在本地端執行:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ssh -L 16001:127.0.0.1:16001 username@server_ip
</span></span></code></pre></div><p>透過特定 Port 與遠端主機連線。</p><p>接著在<strong>遠端主機</strong>執行</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>tensorboard --logdir<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;./logs&#34;</span> --port<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16001</span>
</span></span></code></pre></div><p>同樣的啟動指令，只是規定要在剛剛設定 Port 上啟動服務。</p><p>如此一來就能在自己的主機上查看遠端 Server 的訓練狀況了。</p><hr><h1 id=儲存載入model>儲存、載入Model</h1><p>在訓練完模型後，需要將模型儲存下來，方便日後驗證或使用。
<code>Pytorch</code> 提供了兩種儲存方法: <code>完整模型</code> 以及 <code>State_dict</code></p><h2 id=完整模型>完整模型:</h2><p>官方較不推薦這種方式，由於是透過 <code>pickle</code> 的方式進行儲存，很可能會遭遇意料之外的問題。</p><h3 id=save>Save</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>torch<span style=color:#ff79c6>.</span>save(model, PATH)
</span></span></code></pre></div><h3 id=load>Load</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>load(PATH)
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>eval()
</span></span></code></pre></div><p>在 <code>Pytorch</code> 的 model 中，可以透過 <code>model.train()</code> 以及 <code>model.eval()</code> 來切換不同模式，使用 <code>model.eval()</code> 會將 dropout layer 以及 batch_normalization 切換成驗證模式，避免在 Inference 的過程中造成結果不一致。</p><h2 id=state-dict>State Dict</h2><p>State Dictionary 則是透過 <code>Python 的 Dictionary</code> 來儲存每一層的內容以及權重。如果要查看的話可以透過<code>model.state_dict()</code> 來取得。</p><h3 id=save-1>Save</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>torch<span style=color:#ff79c6>.</span>save(model<span style=color:#ff79c6>.</span>state_dict(), PATH)
</span></span></code></pre></div><h3 id=load-1>Load</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#ff79c6>=</span> MyOwnNet() <span style=color:#6272a4># 要先建立相同的Class Instance.</span>
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>load_state_dict(torch<span style=color:#ff79c6>.</span>load(PATH))
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>eval()
</span></span></code></pre></div><hr><h1 id=使用gpu>使用GPU</h1><p>在上述的內容完成後，基本上已經可以建立一個簡易的 Neural Network 了，接下來紀錄如何將快速的將資料從 CPU 訓練切換為 GPU.</p><p>首先要先確定自己的 <code>Pytorch</code> 是有安裝到 CUDA 版本。
可以透過下列指令確認:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(torch<span style=color:#ff79c6>.</span>cuda<span style=color:#ff79c6>.</span>is_available())
</span></span></code></pre></div><p>如果是 True 則代表有成功偵測到 GPU，若為 False 則可能是設定錯誤！</p><p>接著要建立一個 device 變數:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>device <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>device(<span style=color:#f1fa8c>&#34;cuda&#34;</span> <span style=color:#ff79c6>if</span> torch<span style=color:#ff79c6>.</span>cuda<span style=color:#ff79c6>.</span>is_available() <span style=color:#ff79c6>else</span> <span style=color:#f1fa8c>&#34;cpu&#34;</span>)
</span></span></code></pre></div><p>接著就是將自己的 Model 以及需要送進 Model 的 Input 都轉換為 GPU 模式.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>model <span style=color:#ff79c6>=</span> model<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span>x, y <span style=color:#ff79c6>=</span> x<span style=color:#ff79c6>.</span>to(device), y<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span><span style=color:#6272a4># 以下正常進行使用</span>
</span></span></code></pre></div><p>只要加上短短一行指令即可切換為 GPU 模式，此時如果在 print 這些 tensor，可以發現數值不變，但是後面多了一個"cuda:n" 屬性，這就代表 Tensor 已經被送到 GPU 去了。</p><hr><h1 id=後記>後記</h1><p>在學習 <code>Pytorch</code> 的過程中，很多教材都是語法居多，透過實際進行任務的方式教學，但我在過程中對於許多 Component都似懂非懂，現在稍微釐清後，記錄下來，希望如果是想學習 <code>Pytorch</code> 的入門者，看完這篇文章可以了解一些基本觀念，在看網路上的 Tutorial 或是 Track 別人的 Code 時，能夠不再霧煞煞～</p><hr><ul class=pager><li class=previous><a href=/notes/2020/20200318.html/ data-toggle=tooltip data-placement=top title="安裝 Miniconda 以及 Pytorch">&larr;
Previous Post</a></li><li class=next><a href=/notes/2020/20200416.html/ data-toggle=tooltip data-placement=top title="Pytorch Lightning 入門筆記">Next
Post &rarr;</a></li></ul><hr><div><h2>See Also</h2><div class=card><div class=card-content style=padding:2px><a class="title is-5" href=https://minglunwu.com/notes/2020/20200318.html/>安裝 Miniconda 以及 Pytorch</a>
<span class=heading><time>(March 18, 2020)</time></span></div></div><div class=card><div class=card-content style=padding:2px><a class="title is-5" href=https://minglunwu.com/notes/2025/obsidian_6.html/>Obsidian 入坑指南 #6 : 認識 Core Plugin (下)</a>
<span class=heading><time>(August 21, 2025)</time></span></div></div><div class=card><div class=card-content style=padding:2px><a class="title is-5" href=https://minglunwu.com/notes/2024/obsidian_5.html/>Obsidian 入坑指南 #5 : 認識 Core Plugin (上)</a>
<span class=heading><time>(October 26, 2024)</time></span></div></div></div><hr><script src=https://utteranc.es/client.js repo=MingLunWu/MingLunWu.github.io issue-term=title theme=github-light crossorigin=anonymous async></script><hr><iframe src=https://minglunwu.substack.com/embed width=100% height=320 style="border:1px solid #eee;background:#fff" frameborder=0 scrolling=no></iframe></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/ansible title=ansible>ansible</a>
<a href=/tags/book title=book>book</a>
<a href=/tags/career title=career>career</a>
<a href=/tags/cloud title=cloud>cloud</a>
<a href=/tags/concept title=concept>concept</a>
<a href=/tags/fast-api title=fast-api>fast-api</a>
<a href=/tags/fast-api-tutorial title=fast-api-tutorial>fast-api-tutorial</a>
<a href=/tags/music title=music>music</a>
<a href=/tags/note title=note>note</a>
<a href=/tags/personal title=personal>personal</a>
<a href=/tags/pytest-101 title=pytest-101>pytest-101</a>
<a href=/tags/python title=python>python</a>
<a href=/tags/reflection title=reflection>reflection</a>
<a href=/tags/test title=test>test</a>
<a href=/tags/thought title=thought>thought</a>
<a href=/tags/tool title=tool>tool</a>
<a href=/tags/wsgi title=wsgi>wsgi</a></div></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:alen6997535@gmail.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/minglunwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://www.linkedin.com/in/ming-lun-wu-637020142/><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://medium.com/@minglun-wu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-medium fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Byte and Ink"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Byte and Ink 2025<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){t=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),n=$(this).text(),i=$('<a href="'+o+'" rel="nofollow">'+n+"</a>"),s=$('<li class="'+t+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>