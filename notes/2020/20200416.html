<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="en"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
        <!--- basic page needs
    ================================================== -->
    <meta charset="utf-8">
    <!--
    <meta name="description" content="">
    <meta name="author" content="">
    -->
    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/base.css">
    <!--<link rel="stylesheet" href="https://minglunwu.github.io/theme/css/vendor.css">-->
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/main.css">
    <link rel="stylesheet" href="https://minglunwu.github.io/theme/css/styles.css">

    <!-- script
    ================================================== -->
    <script src="https://minglunwu.github.io/theme/js/modernizr.js"></script>
    <script src="https://minglunwu.github.io/theme/js/pace.min.js"></script>
    <!--<script src="https://kit.fontawesome.com/968a4ded4c.js" crossorigin="anonymous"></script>-->

    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="https://minglunwu.github.io/theme/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://minglunwu.github.io/theme/favicon.ico" type="image/x-icon">

    <title>Pytorch Lightning 入門筆記</title>
    <meta property="og:title" content="Pytorch Lightning 入門筆記">
    <meta name="description" content="<p>Pytorch Lightning 是Pytorch的一種開發框架，目的是在撰寫Deep Learning的模型時，將注意力放在模型本身即可，由此框架來代為處理常見且繁瑣的工作(例如:Optimze、update parameter、check log、save checkpoints等等）。</p>">
    <meta property="og:description" content="<p>Pytorch Lightning 是Pytorch的一種開發框架，目的是在撰寫Deep Learning的模型時，將注意力放在模型本身即可，由此框架來代為處理常見且繁瑣的工作(例如:Optimze、update parameter、check log、save checkpoints等等）。</p>">
    <meta name="author" content="MingLun Allen Wu">
    <meta property="og:image" content="https://images.unsplash.com/photo-1500674425229-f692875b0ab7?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1950&q=80">
    
    <link rel="image_src" type="image/jpeg" href="https://images.unsplash.com/photo-1500674425229-f692875b0ab7?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1950&q=80" />
    <style>
        img{
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
    </style>
</head>

<body id="top">
            <!-- header
    ================================================== -->
    <header class="s-header">

        <div class="header-logo">
            <a class="site-logo" href="https://minglunwu.github.io"><img src="https://minglunwu.github.io/theme/images/logo.png" width="160" height="56" alt="Homepage"></a>
        </div>

        <nav class="header-nav-wrap">
            <ul class="header-nav">
                <li class="current"><a href="https://minglunwu.github.io/#home" title="home">Home</a></li>
                <li><a href="https://minglunwu.github.io/#about" title="about">About</a></li>
                <li><a href="https://minglunwu.github.io/#blog" title="blog">Blogs</a></li>
                <li><a href="https://minglunwu.github.io/#note" title="note">Notes</a></li>
                <!--<li><a class="smoothscroll" href="#note" title="notes">Notes</a></li>-->
                <!--<li><a class="smoothscroll"  href="#contact" title="contact">Contact</a></li>-->
            </ul>
        </nav>

        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->

        <article class="blog-single">

            <!-- page header/blog hero
            ================================================== -->
            <div class="page-header page-header--single page-hero" style="background-image:url(https://images.unsplash.com/photo-1500674425229-f692875b0ab7?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1950&q=80)">
            
                <div class="row page-header__content narrow">
                    <article class="col-full">
                        <div class="page-header__info">
                            <div class="page-header__cat">
                                    <a href="#0">Pytorch</a>
                            </div>
                        </div>
                        <h1 class="page-header__title">
                            <a href="#0" title="">
                                Pytorch Lightning 入門筆記
                            </a>
                        </h1>
                        <ul class="page-header__meta">
                            <li class="date">2020- 4-16 (四)</li>
                            <li class="author">
                                By
                                <span>MingLun Allen Wu</span>
                            </li>
                        </ul>
                        
                    </article>
                </div>
        
            </div> <!-- end page-header -->
    
            <div class="row blog-content">
                <div class="col-full blog-content__main">
                    
                    <ul>
<li><a href="#%e5%89%8d%e8%a8%80">前言</a></li>
<li><a href="#%e5%be%9e%e9%9b%b6%e9%96%8b%e5%a7%8b---pytorch%e5%85%a5%e9%96%80%e6%87%b6%e4%ba%ba%e5%8c%85">從零開始 - Pytorch入門懶人包</a></li>
<li><a href="#%e7%b0%a1%e4%bb%8b">簡介</a></li>
<li><a href="#%e4%b8%80%e5%ae%89%e8%a3%9d">一、安裝</a></li>
<li><a href="#%e4%ba%8c%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5">二、基本概念</a></li>
<li><a href="#%e4%b8%89-research-code">三、 Research Code</a></li>
<li><a href="#%e5%9b%9b%e9%80%8f%e9%81%8etrainer%e8%87%aa%e5%8b%95%e8%a8%93%e7%b7%b4">四、透過Trainer自動訓練</a></li>
<li><a href="#training">Training</a></li>
<li><a href="#evaluation--inference">Evaluation / Inference</a></li>
<li><a href="#%e4%ba%94%e5%be%8c%e8%a8%98">五、後記</a></li>
</ul>
<hr>
<h1>前言</h1>
<p>在了解Pytorch的基本使用後，透過<code>Pytorch Lightning</code>框架能夠讓我們更有效率的進行開發。如果對於Pytorch的基本使用還不熟悉的讀者，可以先看看我先前寫的文章: </p>
<h2><a href="https://minglunwu.github.io/notes/2020/20200324.html">從零開始 - Pytorch入門懶人包</a></h2>
<h1>簡介</h1>
<p>透過Pytorch撰寫Deep Learning相關程式碼時，程式碼大致可分成兩種類型:</p>
<ol>
<li>
<p><strong>依照專案有所不同</strong>: 這類程式碼會根據開發的需求而改變，例如「資料的前處理」、「模型的架構」。</p>
</li>
<li>
<p><strong>跨專案重複使用</strong>: 這類程式碼在每一個應用中都會存在，且相似性非常高，例如「將資料送入DataLoader」、「計算Loss」、「透過Optimizer更新模型的weight」。</p>
</li>
</ol>
<hr>
<p><code>Pytorch Lightning</code>希望替使用者簡化的就是「<strong>跨專案重複使用</strong>」這部分的程式碼，讓使用者能省下精力及時間去處理更為重要的核心模型部分。 </p>
<p>你可以將其視為是一種「樣式指南」(類似Python的PEP8)，透過一定規則將訓練過程中的幾個重要步驟封裝起來(Train, 計算Loss, Optimizer, 更新參數)。</p>
<p>你可能很好奇這樣做的用意是什麼？ 你將可以透過特別的 <code>Trainer</code> Class來進行操作，不再需要花費時間撰寫 Evaluation的Loss、或是在每一個Epoch結束時顯示Loss、固定幾個Step要顯示當前訓練狀態、儲存Validation表現最好的Checkpoint。 <strong>只要你先按照Pytorch Lightning的格式封裝程式碼，在訓練時的瑣碎細節它會幫你處理好。</strong></p>
<p>下面這張圖則是Pytorch Lightning 官網的例子，用來說明Pytorch Lightning 想要簡化的部分。
<img alt="" src="https://pytorch-lightning.readthedocs.io/en/latest/_images/pt_trainer.png"></p>
<p>我們來看個較為實際的例子:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SomeModel</span><span class="p">()</span> <span class="c1"># 假設這是你按照Pytorch Lightning封裝好的Model.</span>
<span class="c1"># 透過GPU訓練</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># 透過CPU訓練</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># 進行Evaluation</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">()</span>
</pre></div>


<p>從上面的範例中可以看到，原先冗長的訓練過程現在只需要透過短短的幾行程式碼即可實現。將訓練時的細節按照特定規則封裝好後，就可直接透過 <code>Trainer</code> Class來進行訓練。</p>
<hr>
<h1>一、安裝</h1>
<p>透過pip即可進行安裝:</p>
<div class="highlight"><pre><span></span>pip install pytorch-lightning<span class="o">==</span><span class="m">0</span>.7.1
</pre></div>


<hr>
<h1>二、基本概念</h1>
<p><code>Pytorch Lightning</code>將深度學習的程式碼分成三種類型:</p>
<ol>
<li>
<p><strong>Research Code</strong>:
    整個應用的核心架構，可能會根據任務的內容進行調整、或是在開發過程中加入自己的想法。通常可能會包含幾個核心元件:</p>
<ul>
<li>模型架構定義</li>
<li>Train/Val/Test資料切分</li>
<li>Optimizer定義</li>
<li>Train/Val/Test Step Computation.</li>
</ul>
</li>
<li>
<p><strong>Engineer Code</strong>:</p>
<p>「EarlyStopping」, 「將資料送入GPU」等常見且不同專案使用方式都類似的程式碼。這部分的程式碼是 <code>Pytorch Lightning</code>最希望能簡化的。</p>
</li>
<li>
<p><strong>Non-Essential Code</strong>:</p>
<p>檢查梯度、視覺化等偏向輔助性質的功能。</p>
</li>
</ol>
<p><code>Pytorch Lightning</code>希望使用者只需要定義<strong>Research Code</strong>，而<strong>Engineer Code</strong>由它來代為處理、<strong>Non-Essential</strong>則是根據使用者的需要自行選用，由於不會影響正常使用，接下來我們著重探討如何重新將<strong>Research Code</strong>組織為<code>Pytorch Lightning</code>的格式。</p>
<hr>
<h1>三、 Research Code</h1>
<p>針對模型開發中最為重要的就是 Research Code了，在 <code>Pytorch Lightning</code>中透過 <code>pl.LightningModule</code>模組來實現，這個模組繼承了<code>torch.nn.Module</code>的功能，所以使用上其實跟使用原生Pytorch是相當類似的。</p>
<p>實作時只需在定義的Class上繼承pl.LightningModule即可。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="k">class</span> <span class="nc">YourOwnNet</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">somemethod</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></div>


<p>在繼承 <code>pl.LightingModule</code>後，有幾項重要的Method必須被Override，未來 <code>Pytorch Lightning</code>才能自動地進行訓練，以下將這些方法及目的條列出來:</p>
<ul>
<li>
<h4><strong>prepare_data()</strong>:</h4>
<p>負責資料的載入(包含Training Set, Evaluation Set, Test)都撰寫在方法中。 自動訓練時會優先執行此Method以獲取資料。</p>
</li>
<li>
<h4><strong>configure_optimizer(self)</strong>:</h4>
<ul>
<li><strong>回傳特定的優化器</strong> (torch.nn.optimizer)</li>
<li>如果對於優化的參數有任何設定(例如只想對特定參數進行調整)，也是在這個地方調整。</li>
<li>在自動訓練時，會呼叫此方法來取得Optimizer。</li>
</ul>
<p>:::python
def configure_optimizers(self):
        return Adam(self.parameters(), lr=1e-3)</p>
</li>
<li>
<h4><strong>train_dataloader(self)</strong> / <strong>val_dataloader(self)</strong> / <strong>test_dataloader(self)</strong>:</h4>
<ul>
<li><strong>回傳<code>Pytorch</code>的 <code>DataLoader</code> Object</strong>，</li>
<li>這三個方法定義了training/ validation/ test時使用的DataLoader。其中會使用到的資料可以透過 <code>prepare_data()</code>先行取得。</li>
<li>在自動訓練的過程中，會呼叫這邊定義的Function來取得不同時期(Train/Validation/Test)的DataLoader。</li>
</ul>
<p>:::python
def train_dataloader(self):
    # self.train_dataset 通常由 self.prepare_data()產生.
    return DataLoader(self.train_dataset, batch_size= self.batch_size, shuffle=True) </p>
</li>
<li>
<h4><strong>forward(self, args)</strong>:</h4>
<ul>
<li>
<p>定義當前這個模型forward propagation時所要進行的動作。 </p>
</li>
<li>
<p>特別注意在建立instance時，直接將參數傳入instance等同於呼叫forward function。來個具體例子。</p>
</li>
</ul>
<p>:::python
model = TestModel()
x = torch.Tensor([1, 2, 3])
output1 = model(x)
output2 = model.forward(x)</p>
<p>output1 == output2  # 實際上這兩個是相同的.</p>
</li>
<li>
<h4><strong>training_step/val_step/test_step(self, batch, batch_idx)</strong>:</h4>
<ul>
<li>
<p>分別定義了traing/ validation/ test時的每一個Step所要進行的任務，其中較特別的是參數<code>batch</code>, <code>batch_idx</code>，這是會自動從<code>train/val/test_dataloader()</code>中的<code>DataLoader</code>取出一個batch。具體使用方式請見下方範例。</p>
</li>
<li>
<p>此類型方法的回傳值有一定的格式，需要回傳一個Python的Dictionary，其中包含:</p>
<ul>
<li>loss: 當前Step計算出來的Training Loss. 用於接下來的Backward Propagation及參數調校。</li>
<li>log: 包含當前訓練的狀況，在訓練時會自動回傳成進度條。 如下圖所示:
<img alt="" src="https://minglunwu.github.io/theme/images/20200414.png"></li>
</ul>
<p>:::python
def training_step(self, batch, batch_idx):
    x, y = batch  # 這裡的batch會對應到 self.train_dataloader()所回傳的DataLoader Object，對其取用一個batch.</p>
<div class="highlight"><pre><span></span><span class="err">output = self.forward(x) # 將Input進行 forward propagation.</span>
<span class="err">criterion = nn.CrossEntropyLoss()</span>
<span class="err">loss = criterion(output, y)</span>
<span class="err">logs = {&quot;loss&quot;: loss}</span>
<span class="err">return {&quot;loss&quot;: loss, &quot;log&quot;: logs}</span>
</pre></div>


</li>
</ul>
</li>
<li>
<h4><strong>(training/validation/test)_epoch_end(self, outputs)</strong>:</h4>
<ul>
<li>定義了「不同時期訓練完一個epoch時需要執行的事項」，舉例來說可能會在Validation的一個Epoch結束時計算所有Step平均的Loss是多少。</li>
<li><code>outputs</code> 參數為「當前Epoch中所有Step的{"loss": loss, "logs": logs}」(也就是每一個self.training_step()的回傳值)。</li>
<li>
<p>以下範例示範了在「每一個Validation Epoch結束後計算Average Loss」。</p>
<p>:::python
def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
        avg_val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()</p>
<div class="highlight"><pre><span></span><span class="err">    tensorboard_logs = {&#39;val_loss&#39;: avg_loss, &#39;avg_val_acc&#39;: avg_val_acc}</span>
<span class="err">    return {&#39;avg_val_loss&#39;: avg_loss, &#39;progress_bar&#39;: tensorboard_logs}</span>
</pre></div>


</li>
</ul>
</li>
<li>
<h4>統整版本:</h4>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PytorchLightningModel</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span> <span class="c1"># 這邊一定要繼承pl.LightningModule</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># 初始化時可以將基本設定傳入。</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># 此方法會在初始化後優先執行。 所以可以在此方法中先將會用到的資料都讀取進來.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_set</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">)</span> <span class="c1"># read_data是自定義的讀取資料Method. 可以按照自己需求調整</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_set</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_set</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;===== Data is ready... =====&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># 自動訓練時會呼叫此方法來獲取Optimizer.</span>
        <span class="k">return</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span> <span class="c1"># 這邊注意要調整的參數是`self.parameters()`</span>

    <span class="c1"># 以下三個方法則是設定進行訓練及驗證時所要使用的Data Loader格式。</span>
    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c1"># 定義模型在forward propagation時如何進行.</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span> <span class="c1"># 定義訓練過程的Step要如何進行</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span> <span class="c1"># 從self.train_dataloader()的Data Loader取一個batch出來。</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span><span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span><span class="n">logs</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span> <span class="c1"># 定義Validation如何進行，以這邊為例就再加上了計算Acc.</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># acc</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;val_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span> <span class="c1"># 在Validation的一個Epoch結束後，計算平均的Loss及Acc.</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">avg_val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;val_acc&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="n">tensorboard_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;val_loss&#39;</span><span class="p">:</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="s1">&#39;avg_val_acc&#39;</span><span class="p">:</span> <span class="n">avg_val_acc</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;avg_val_loss&#39;</span><span class="p">:</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="s1">&#39;progress_bar&#39;</span><span class="p">:</span> <span class="n">tensorboard_logs</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span> <span class="c1">#定義 Test 階段</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># acc</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">}</span>
</pre></div>


</li>
</ul>
<hr>
<h1>四、透過Trainer自動訓練</h1>
<h2>Training</h2>
<p>在你重新將程式碼改寫為<code>Pytorch Lightning</code>格式後，輕鬆的部分來了！接下來我們只需要透過<code>Trainer</code> Class即可自動處理訓練。我們看看以下的範例:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">PytorchLightningModel</span><span class="p">(</span><span class="n">param1</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># 自行封裝成Pytorch Lightning的模型</span>

<span class="c1"># Trainer 有不同的參數可以調整訓練時的行為</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">()</span> <span class="c1"># 使用CPU</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 使用GPU</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#訓練時，使用單一個batch作為ㄧ個Epoch，目的是快速的確認當前的模型設置有無結構上的問題(快速地跑完Train -&gt; Validation -&gt; Test)。</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># 呼叫.fit() 就會自動進行Model的training step及validation step.</span>
</pre></div>


<p>原先從CPU切換為GPU，可能需要針對所有的變數、模型進行裝置的變更。<strong>但現在只需要調整Trainer的<code>gpus</code>參數即可</strong>。</p>
<p>而訓練時如果需要以dry-run的方式，確定Model從頭到尾的結構沒有問題，現在也只需要設定<code>fast_dev_run</code>即可。</p>
<p>另外Trainer Class也針對了「使用多張GPU」、「accumulate_grad_batches」提供參數進行調整，細節的部分可以參考官方網站。 <a href="https://pytorch-lightning.readthedocs.io/en/latest/trainer.html">連結在此</a></p>
<h2>Evaluation / Inference</h2>
<p>在訓練完模型後，你也能夠載入先前訓練好的Checkpoint File並且重新進行Evaluation/Inference.</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">PytorchLightningModel</span><span class="p">(</span><span class="n">param1</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">param2</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># 自行封裝成Pytorch Lightning的模型</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">resume_from_checkpoint</span><span class="o">=</span><span class="s2">&quot;PATH&quot;</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>


<hr>
<h1>五、後記</h1>
<p>從原生Pytorch 轉移到 <code>Pytorch Lightning</code>並不需要花費過多成本來學習新的語法，其概念只是將程式碼「重新組織」，將對應的程式碼放置到特定的Method中，如此一來在進行訓練時，將能省下許多工程面的實作時間、程式碼也會變得簡潔許多。</p>
    
                    <p class="blog-content__tags">
                        <span>Post Tags</span>
    
                        <span class="blog-content__tag-list">
                             <a href="#0">Pytorch</a>
                        </span>
    
                    </p>
    
                    <div class="blog-content__pagenav">
                        <div class="blog-content__nav">










                            <div class="blog-content__prev">
                                <a href="https://minglunwu.github.io/notes/2020/20200520.html" rel="prev">
                                    <span>Previous Post</span>
                                    Python 平行化運算 - Multi-Processing
                                </a>
                            </div>
                            <div class="blog-content__next">
                                <a href="https://minglunwu.github.io/notes/2020/20200324.html" rel="next">
                                    <span>Next Post</span>
                                    從零開始 - Pytorch 入門懶人包
                                </a>
                            </div>
                        </div>
    
                        <div class="blog-content__all">
                            <a href="https://minglunwu.github.io/#note" class="btn btn--primary">
                                View All Post
                            </a>
                        </div>
                    </div>
    
                </div><!-- end blog-content__main -->
            </div> <!-- end blog-content -->
    
        </article>
            <!-- footer
    ================================================== -->
    <footer>
        <div class="row">
            <div class="col-full">

                <div class="footer-logo">
                    <a class="footer-site-logo" href="#0"><img src="https://minglunwu.github.io/theme/images/logo.png" alt="Homepage"></a>
                </div>
                <ul class="footer-social">
                    <li>
                        <a href="https://www.facebook.com/zebra52000" target="_blank"><i class="im im-facebook" aria-hidden="true"></i><span>Facebook</span></a>
                    </li>
                    <li>
                        <a href="https://medium.com/@allen6997535" target="_blank"><i class="im im-book" aria-hidden="true"></i><span>Medium</span></a>
                    </li>
                    <li>
                        <a href="https://github.com/MingLunWu" target="_blank"><i class="im im-github" aria-hidden="true"></i><span>Github</span></a>
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/allen-ming-lun-wu-637020142/" target="_blank"><i class="im im-linkedin" aria-hidden="true"></i><span>LinkedIn</span></a>
                    </li>
                    <li>
                        <a href="https://www.instagram.com/whoisfater0724/" target="_blank"><i class="im im-instagram" aria-hidden="true"></i><span>Instagram</span></a>
                    </li>
                </ul>
                    
            </div>
        </div>

        <div class="row footer-bottom">

            <div class="col-twelve">
                <div class="copyright">
                    <span>© Copyright Hola 2017</span> 
                    <span>Design by <a href="https://www.styleshout.com/">styleshout</a></span>	
                </div>

                <div class="go-top">
                <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
                </div>
            </div>

        </div> <!-- end footer-bottom -->

    </footer> <!-- end footer -->
    <!-- Java Script
        ================================================== -->
        <script src="https://minglunwu.github.io/theme/js/jquery-3.2.1.min.js"></script>
        <script src="https://minglunwu.github.io/theme/js/plugins.js"></script>
        <script src="https://minglunwu.github.io/theme/js/main.js"></script>

</body>